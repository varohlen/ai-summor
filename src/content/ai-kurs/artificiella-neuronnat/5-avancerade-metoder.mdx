---
title: '5. Avancerade neuronnätsmetoder'
description: 'Upptäck moderna AI-tekniker: faltningsnät för bildbehandling, generativa tävlande nätverk och transformers som driver ChatGPT.'
order: 5
pubDate: 2025-10-06
draft: true
---

import MultipleChoiceQuiz from '../../components/MultipleChoiceQuiz.astro';
import FillInQuiz from '../../components/FillInQuiz.astro';

## Avancerade neuronnätsmetoder

De modeller och metoder vi nämnde tidigare, såsom flerlagers neuronnät, olinjära aktiveringsfunktioner (t.ex. sigmoidfunktion) och backpropagation-algoritmen, formar grunden för moderna, avancerade neuronnätsmetoder.

Dessutom är de principer som har lett till resultatet, och som för bara några år sedan ansågs vara nästan omöjliga, relativt enkla. Utöver dem har det dock även behövts nya, intressanta idéer.

---

## Faltningsnät (Convolutional Neural Networks)

De framsteg som har gjorts inom djupinlärning, speciellt inom bildbehandling, har varit nära nog **svindlande**. 

### Problemet med vanliga neuronnät

Begränsningarna med den enkla neuronnätklassificerare som vi nämnde i förra kapitlet uppnåddes fort – vilket du säkert märkte i smilisuppgiften. 

Att öka antalet neuroner och lager i nätet och tillämpa backpropagation-algoritmen underlättar i princip processen, men i det långa loppet stöter vi på ett annat problem:

> [!WARNING] Exploderande parametrar
> Antalet vikter i modellen ökar **drastiskt** och mängden data som behövs för träning blir större än vad någon har tillgång till (inte ens Google).

### Lösningen: Faltningslager

Som tur är det här ingen katastrof och det finns en elegant lösning på problemet: en speciell neuronnätmodell, eller rättare sagt ett speciellt format lager, som kan läggas till vilket neuronnät som helst. 

Lagret kallas för ett **faltningslager**. Neuronnät som innehåller faltningslager kallas för **faltningsnät** (eng. convolutional neural network, CNN).

*[PLATSHÅLLARE FÖR BILD: Illustration av faltningslager som känner igen kanter]*

### Vad kan faltningslager göra?

Med hjälp av faltningslager kan man känna igen olika **särdrag i bilderna** (eng. image features), såsom:

**Enkla särdrag:**
- Klara eller mörka fläckar
- Färgfläckar
- Kanter som löper åt olika håll
- Enkla figurer

**Komplexa särdrag:**
- Kattens öra
- Hundens nos
- Människans öga
- Den åttakantiga formen på en stoppskylt

<MultipleChoiceQuiz 
  question="Vad är det största problemet med att bara lägga till fler neuroner i ett vanligt neuronnät?"
  options={[
    "Datorn blir för långsam",
    "Antalet vikter och mängden träningsdata som behövs blir astronomiskt stort",
    "Neuronen slutar fungera",
    "Bilderna blir för stora"
  ]}
  correctAnswer={1}
  explanation="När vi lägger till fler neuroner ökar antalet vikter dramatiskt. Ett neuronnät med miljontals vikter kräver enorma mängder träningsdata, vilket är opraktiskt. Faltningsnät löser detta genom att återanvända samma vikter på olika delar av bilden!"
/>

### Varför är faltningsnät så kraftfulla?

Utan faltningslager skulle det vara svårt att lära neuronnätet att känna igen sådana här drag eftersom de kan förekomma:
- **Var som helst** på bilden
- I **olika positioner**
- I **olika storleksformat**

Att flytta på objektet eller kameran kan orsaka drastiska förändringar i pixelvärdena, trots att vi tycker att objektet ser ut som det gjorde förut.

**Exempel:** En stoppskylt i högra hörnet skulle endast observeras om träningsdata innehåller en bild med en stoppskylt i högra hörnet. Faltningsnät kan känna igen objektet **oavsett var på bilden** skylten är placerad.

> [!NOTE] Hemligheten: Återanvända vikter
> I faltningsnät används en enkel metod för att minimera mängden data till en bråkdel. Idén är att man använder **samma vikter i flera neuroner**, varvid de känner igen samma objekt – utifrån olika indata.
> 
> Det kan till exempel finnas en grupp neuroner som aktiveras då de känner igen kattens spetsiga öra. Om indata är en bild på en katt, aktiveras två neuroner: ett för det vänstra och ett för det högra örat.

### Hur faltningsnät är uppbyggda

Faltningslagret placeras oftast som de **understa lagren** som direkt behandlar pixlarna i bilden. Man kan använda vanliga neuroner i de övre lagren. 

**Träningsprocess:**

1. **Understa lagren** (faltningslager)
   - Tränas med oövervakat lärande
   - Lär sig vanligt förekommande särdrag
   - Kan återanvändas för olika uppgifter

2. **Översta lagren** (vanliga neuroner)
   - Tränas med övervakat lärande (backpropagation)
   - Kräver klassificerade data
   - Specialiserade för specifik uppgift

*[PLATSHÅLLARE FÖR BILD: Arkitektur av CNN med olika lager]*

<FillInQuiz 
  question="Vilken typ av lärande används för att träna de understa lagren i ett faltningsnät?"
  correctAnswer={["oövervakat", "oövervakat lärande", "unsupervised"]}
  caseSensitive={false}
  explanation="De understa lagren tränas med oövervakat lärande, vilket betyder att de lär sig mönster utan att vi behöver märka upp data. Detta är smidigt eftersom det finns gränslösa mängder oklassificerade bilder!"
/>

---

## Generativa Tävlande Nätverk (GAN)

Efter att ha tränat ett neuralnätverk på data kan vi använda det för att göra förutsägelser. Men vad händer om vi vill **skapa** nya bilder istället?

### DeepDream och neuronnätets "drömmar"

Särdrag och objekt som de understa lagren har lärt sig kan åskådliggöras genom att man producerar bilder som aktiverar vissa neuroner i nätet. På så sätt får vi se hur neuronnätet "ser" olika begrepp.

Det har till och med sagts att vi kan se neuronnätens **"drömmar"** eller **"hallucinationer"** genom detta – Googles DeepDream är ett exempel på det här.

> [!WARNING] Var försiktig med metaforer
> När det gäller neuronnät är det bra att komma ihåg att det alltid handlar om att utgående från befintliga data optimera vikter i en matematisk modell. 
> 
> Ett neuronnät **"drömmer"** eller **"hallucinerar"** aldrig och neuronnätet **"förstår"** inte begreppet katt på samma sätt som en människa gör. Den har blivit tränad i att känna igen objekt eller att producera bilder som liknar bilderna i dess träningsdata.

### Ian Goodfellows briljanta idé

DeepDream-appen genererar konstiga bilder med drag av katt- eller människoansikten, men man ser genast att de är artificiella. 

**Ian Goodfellow**, då en forskare vid Google Brain, fick en briljant idé för hur man kan skapa bilder som ser verkliga ut: genom att sätta ihop **två neuronnät** och låta dem **tävla mot varandra**.

### Hur GAN fungerar

**1. Det generativa nätverket (Generator)**
- Tränas för att generera bilder som liknar dem i träningsdata
- Försöker "lura" det särskiljande nätverket
- Blir bättre och bättre på att skapa realistiska bilder

**2. Det särskiljande nätverket (Discriminator)**
- Tränas för att skilja genererade bilder från verkliga bilder
- Försöker "avslöja" det generativa nätverket
- Blir bättre och bättre på att upptäcka falska bilder

*[PLATSHÅLLARE FÖR BILD: Diagram över GAN-arkitektur med generator och discriminator]*

### Tävlingen

Dessa två nätverk kombinerat utgör sedan ett **generativt tävlande nätverk** (eng. generative adversarial network, GAN).

Två parallella nätverk som formar ett GAN tränar man **samtidigt**:

1. I början har discriminatorn en lätt uppgift att avslöja generatorn
2. Generatorn blir dock så småningom bättre och bättre
3. Till sist måste även discriminatorn bli bättre
4. Tävlingen mellan de två nätverken får båda att utvecklas
5. I bästa fall kan inte ens det mänskliga ögat skilja de genererade bilderna från verkliga bilder

> [!INFO] NVIDIA:s GAN
> GAN nöjer sig inte enbart med att reproducera bilder i träningsdatan, utan skapar **helt nya bilder** som ser verkliga ut.
> 
> Bilderna nedan har producerats med ett GAN utvecklat av NVIDIA, under ledning av Jaakko Lehtinen. Hade du själv kunnat märka att personerna i bilderna inte finns på riktigt, alltså att bilderna är helt syntetiska?

*[PLATSHÅLLARE FÖR BILD: Exempel på GAN-genererade ansikten]*

<MultipleChoiceQuiz 
  question="Vad är syftet med det 'särskiljande nätverket' (discriminator) i ett GAN?"
  options={[
    "Att generera nya bilder",
    "Att skilja verkliga bilder från genererade bilder",
    "Att komprimera bilder",
    "Att färglägga svartvita bilder"
  ]}
  correctAnswer={1}
  explanation="Discriminatorn försöker skilja verkliga bilder från falska (genererade) bilder. Genom denna tävling blir både generatorn och discriminatorn bättre och bättre, tills generatorn kan skapa bilder som ser helt verkliga ut!"
/>

---

## Sammanfattning

> [!TIP] Nyckelkoncept
> - **Faltningsnät (CNN)** = Återanvänder vikter för att känna igen mönster var som helst i bilden
> - **Särdrag** = Enkla mönster (kanter, färger) som kombineras till komplexa objekt
> - **GAN** = Två nätverk som tävlar: ett genererar bilder, ett försöker avslöja dem
> - **Oövervakat lärande** = Träning utan märkt data, används för understa lagren
> - **Metaforer är farliga** = Neuronnät "drömmer" eller "förstår" inte på riktigt

Du har nu lärt dig om de avancerade tekniker som driver modern bildbehandling och bildgenerering!

---

**Nästa steg:** I nästa lektion ska vi utforska den senaste revolutionen inom AI: stora språkmodeller, transformers och ChatGPT!
