---
title: '3. Perceptron och neuronnät'
description: 'Lär dig om perceptronen - alla neuronnäts moder - och hur man bygger de första enkla neuronnäten genom att koppla ihop neuroner i lager.'
order: 3
pubDate: 2025-10-06
---

import MultipleChoiceQuiz from '../../../components/MultipleChoiceQuiz.astro';
import FillInQuiz from '../../../components/FillInQuiz.astro';
import Glossary from '../../../components/Glossary.astro';

## Från en neuron till ett nätverk

En enskild neuron är bra på att fatta enkla, linjära beslut. Men verkligheten är sällan så enkel. Hur känner en AI igen din mormor på ett foto?

En neuron kan kanske lära sig att känna igen en vertikal linje i en bild. En annan kan lära sig känna igen en horisontell linje. Var för sig är de ganska begränsade.

Men om vi **kopplar ihop många neuroner i lager** kan vi skapa ett neuronnät som kan lära sig otroligt komplexa mönster!

---

## Perceptron: Alla neuronnäts moder

**Perceptron** är helt enkelt ett tjusigt namn på en enkel neuron vars aktiveringsfunktion är en stegfunktion. Detta var en av de första modellerna som tillämpades för neurala beräkningar, och eftersom den har en så central roll i neuronnätets historia, kan den med goda skäl kallas för **alla artificiella neuronnäts moder**.

### Frank Rosenblatt och perceptronalgoritmen

År 1957 presenterade psykologen **Frank Rosenblatt** perceptronalgoritmen - en metod för att lära perceptronen rätt vikter från data. Principen är enkel:

1. Mata in ett träningsexempel i neuronen
2. Kontrollera om klassificeringen är rätt
3. Om den är fel, justera vikterna
4. Upprepa tills neuronen klassificerar rätt

Perceptroner kan användas som enkla klassificerare med två olika klasser - till exempel "katt eller hund", "spam eller inte spam", "godkänd eller underkänd". I föregående lektion använde vi oss av perceptron för att veta om en robot ska vattna eller inte och att känna igen bilder.

<MultipleChoiceQuiz 
  quizId="perceptron-def"
  question="Vad är en perceptron?"
  options={[
    "En neuron med sigmoidfunktion",
    "En neuron med stegfunktion",
    "Ett helt neuronnät",
    "En träningsalgoritm"
  ]}
  correctAnswer={1}
  explanation="En perceptron är en neuron som använder en stegfunktion som aktiveringsfunktion. Den kan bara ge två olika utdata: 0 eller 1."
/>

### AI-hypen på 1960-talet

Perceptronalgoritmen fick **väldigt mycket uppmärksamhet** direkt efter att den utvecklades. Frank Rosenblatt spelade en viktig roll för det uppvaknande intresset. 

Ett klassiskt exempel på AI-hypen är en artikel publicerad i **New York Times den 8 juni 1958**:

> "USA:s flotta har i dag visat ett embryo till en elektronisk dator och den förväntas kunna gå, tala, se och föröka sig själv och dessutom bli medveten om sin egen existens."

Låter det bekant? Samma typ av överdrivna förväntningar ser vi även idag när nya AI-genombrott presenteras!

> Både neuronnätsentusiasmen på 60-talet och entusiasmen kring expertsystem på 80-talet fick ett snöpligt slut när inga genombrott kom och finansieringen för forskning rasade – följden blev så kallade **AI-vintrar**.
> 
> Debatten kring neuronnät ledde till att man under två årtionden nästan helt övergav tekniken. Först på 2000-talet, med mer data och bättre datorer, kom neuronnäten tillbaka.

<MultipleChoiceQuiz 
  quizId="ai-vinter"
  question="Vad är en 'AI-vinter'?"
  options={[
    "När AI-system inte fungerar i kallt väder",
    "En period då AI-forskningen stagnerade på grund av bristande framsteg",
    "När neuroner slutar fungera",
    "En ny typ av neuronnät"
  ]}
  correctAnswer={1}
  explanation="En AI-vinter är en period då överdrivna förväntningar inte infrias, vilket leder till minskad finansiering och intresse för AI-forskning. Detta hände både på 1970-talet och 1980-talet."
/>

---

## Neuronnätets arkitektur

Arkitekturen, dvs. strukturen i neuronnätet, är oftast ordnad så att neuronerna har delats in i flera **lager**:

**Indatalagret** 
- Omfattar de neuroner som får sina indata utifrån
- Till exempel pixlar i en bild som visas för nätet
- Detta är neuronnätets indata

**Dolda lager**
- Ett eller flera lager mellan indata och utdata
- Får sina indata från andra neuroner
- Ger sina utdata till andra neuroner
- Här sker den "magiska" bearbetningen

**Utdatalagret**
- Producerar utdata från hela nätet
- Till exempel "katt" eller "hund" i en klassificerare

### Hierarkisk inlärning

Genom att koppla ihop neuroner i lager kan ett neuronnät lära sig komplexa mönster hierarkiskt:

**1. Första lagret (enkla mönster)**
- Känner igen grundläggande saker: kanter, hörn, färgfläckar

**2. Mellanliggande lager (kombinationer)**
- Kombinerar enkla mönster till mer komplexa
- Exempel: kanter → former → delar av objekt

**3. Sista lagren (komplexa strukturer)**
- Känner igen hela objekt: ansikten, djur, föremål

<MultipleChoiceQuiz 
  quizId="lager-forsta"
  question="Vad känner neuroner i det första lagret igen i ett bildigenkänningsnätverk?"
  options={[
    "Hela ansikten",
    "Komplexa objekt",
    "Enkla kanter och linjer",
    "Färger"
  ]}
  correctAnswer={2}
  explanation="Första lagret känner igen de enklaste byggstenarna: kanter, hörn och färgfläckar. Senare lager kombinerar dessa till mer komplexa mönster!"
/>

> [!NOTE] Djupinlärning
> **Djupinlärning** syftar på denna lagerstruktur: ju fler lager, desto djupare nät. 
> 
> Djupet gör det svårare för nätet att lära sig och det förutsätter både större mängder data och större beräkningskapacitet. Om dessa förutsättningar finns ger de dock möjligheten för nätet att lära sig mer komplexa fenomen.

<FillInQuiz 
  quizId="lager-antal"
  question="Om ett neuronnät har 1 indatalager, 5 dolda lager och 1 utdatalager, hur många lager har nätet totalt?"
  correctAnswer={["7", "7 lager", "sju"]}
  type="text"
  explanation="Totalt 7 lager: 1 indatalager + 5 dolda lager + 1 utdatalager = 7 lager. Ju fler dolda lager, desto 'djupare' är nätet!"
/>

### Hur tränar man ett neuronnät?

Perceptronalgoritmen som Rosenblatt utvecklade fungerar bra för en enskild neuron. Men hur tränar man ett helt nätverk med många lager?

Detta var länge ett olöst problem. Att justera vikterna i ett flerlagers neuronnät var en utmaning av ett helt annat slag.

### Backpropagation: Lösningen

Till slut hittade man en lösning: **backpropagation-algoritmen**. Den bidrog till att neuronnäten återuppstod i slutet av 80-talet och utgör fortfarande kärnan för hur moderna neuronnät tränas.

**Så här fungerar backpropagation:**

1. **Framåt** - Mata in data genom nätet
2. **Jämför** - Se hur långt ifrån rätt svar vi är
3. **Beräkna fel** - Hur mycket har vi fel?
4. **Bakåt** - Skicka felet bakåt genom nätet (därav namnet!)
5. **Justera** - Ändra vikterna baserat på hur mycket varje neuron bidrog till felet

Genom att upprepa detta tusentals gånger lär sig nätet gradvis att göra bättre förutsägelser.

<MultipleChoiceQuiz 
  quizId="backprop"
  question="Vad gör backpropagation-algoritmen?"
  options={[
    "Skickar data framåt genom nätet",
    "Justerar vikterna bakåt genom nätet för att minska felet",
    "Skapar nya neuroner",
    "Tar bort onödiga lager"
  ]}
  correctAnswer={1}
  explanation="Backpropagation skickar felet bakåt (därav namnet!) genom nätet och justerar vikterna i varje lager baserat på hur mycket de bidrog till felet. Detta är grunden för hur moderna neuronnät tränas."
/>

## Sammanfattning

> [!TIP] Nyckelkoncept
> - **Perceptron** = En neuron med stegfunktion, utvecklad av Frank Rosenblatt 1957
> - **AI-vintrar** = Perioder då överdrivna förväntningar ledde till minskad finansiering
> - **Neuronnät** = Många neuroner kopplade i lager (indata, dolda, utdata)
> - **Djupinlärning** = Neuronnät med många dolda lager
> - **Backpropagation** = Algoritm som tränar neuronnät genom att skicka fel bakåt

Du har nu lärt dig historien bakom neuronnät och hur man bygger dem genom att koppla ihop neuroner i lager!

<Glossary 
  terms={[
    "Perceptron",
    "AI-vinter",
    "Neuronnät",
    "Indatalager",
    "Dolt lager",
    "Utdatalager",
    "Djupinlärning",
    "Backpropagation"
  ]}
/>

---

**Nästa steg:** I nästa lektion ska vi se hur man kan använda enkla neuronnät för att klassificera bilder, och du får prova på att träna din egen klassificerare!
