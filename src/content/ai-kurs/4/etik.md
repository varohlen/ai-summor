---
title: 'AI och etik'
description: 'Vad är etik i AI, varför spelar det roll, och vilka verkliga exempel visar hur svårt ansvar kan vara?'
order: 2
tags:
  - etik
  - konsekvenser
  - diskussion
---

## AI och etik

AI påverkar redan hur vi får information, söker jobb, får vård och blir bedömda i skolan.

När vi pratar om **etik** i AI handlar det om frågor som:
- Vad är rättvist?
- Vem kan skadas?
- Vem bär ansvar när något går fel?
- Hur skyddar vi människor som är extra sårbara?

Etik är alltså inte bara "vad som är tillåtet" i lagens mening. Det handlar också om vad som är rimligt, mänskligt och ansvarsfullt.

---

## Fyra vanliga etiska problem

### 1. Bias och diskriminering

AI lär sig av data från verkligheten. Om data innehåller gamla mönster av orättvisor kan AI förstärka dem.

Exempel:
- Ett rekryteringssystem kan börja favorisera vissa grupper.
- Ett ansiktsigenkänningssystem kan fungera sämre för personer med mörkare hudton.

### 2. Ansvar

Om en AI rekommenderar något skadligt, vem är ansvarig?
- Den som byggde modellen?
- Organisationen som använder den?
- Personen som klickade "godkänn"?

I praktiken delas ansvar ofta mellan flera aktörer, men det gör det också lätt att "ingen" tar fullt ansvar.

### 3. Transparens

Många AI-system är svåra att förstå, även för experter. Det blir ett problem när AI används i viktiga beslut.

Om du inte kan förklara *varför* ett beslut togs, hur kan du då ifrågasätta det?

### 4. Psykologisk påverkan

AI-chattar kan upplevas mänskliga. För vissa är det hjälpsamt, för andra kan det bli skadligt, särskilt vid ensamhet eller psykisk ohälsa.

---

## Verkliga exempel

### Exempel A: Rekrytering och snedvridning

Ett uppmärksammat exempel är när ett AI-system för rekrytering visade tydlig snedvridning mot kvinnor i tekniska roller. Systemet tränades på historiska anställningar och lärde sig därför gamla mönster i stället för att skapa rättvisa beslut.

<details>
<summary><strong>Källor - Exempel A</strong></summary>

- [Reuters (2018) - Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G/)

</details>

### Exempel B: Ansiktsigenkänning och felidentifiering

Flera studier och händelser har visat att ansiktsigenkänning kan ge fler fel för vissa grupper. När sådan teknik används av myndigheter eller polis kan konsekvenserna bli mycket allvarliga för den som drabbas.

<details>
<summary><strong>Källor - Exempel B</strong></summary>

- [Gender Shades (MIT Media Lab, 2018)](https://gendershades.org/overview.html)
- [NIST FRVT Demographic Effects (2019)](https://www.nist.gov/publications/face-recognition-vendor-test-frvt-part-3-demographic-effects)
- [NIST FRTE Ongoing (2024)](https://pages.nist.gov/frvt/html/frvt11.html)

</details>

### Exempel C: AI-chattar och psykisk hälsa

Det har förekommit fall där familjer menar att unga personer påverkats negativt efter långvariga samtal med AI-chattar. Flera sådana händelser är juridiskt omtvistade, men de visar hur stark relationen till AI kan bli och hur svårt ansvarsfrågan är.

<details>
<summary><strong>Källor - Exempel C</strong></summary>

- [The Washington Post (2025) - Rapportering om AI-kompanjoner och psykisk påverkan](https://www.washingtonpost.com/technology/2025/02/24/ai-chatbots-mental-health-crisis/)
- [NPR (2024) - Familj stämmer Character.AI efter tonårings död](https://www.npr.org/2024/10/30/nx-s1-5170279/character-ai-lawsuit)
- [AP News (2025) - Stämningar kring AI-chatbots och psykisk ohälsa](https://apnews.com/article/ai-chatbots-lawsuits-mental-health)

</details>

---

## Etiska glasögon att använda

När ni analyserar AI-frågor kan ni testa olika perspektiv:

- **Konsekvensetik:** Vad leder till mest nytta och minst skada?
- **Pliktetik:** Finns handlingar som är fel även om utfallet blir bra?
- **Rättviseetik:** Vem gynnas och vem missgynnas?
- **Ansvarsetik:** Vem hade makt att förebygga problemet?

---

## Inför case-diskussionen

Målet är inte att hitta "ett rätt svar". Målet är att kunna:
- se flera perspektiv samtidigt,
- argumentera tydligt,
- och motivera vem som bör ta ansvar och varför.

Nästa steg: [AI och etik - Case-diskussion](../etik-case)

---

## Samlade källor

- [Reuters (2018) - Amazon recruiting tool bias](https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G/)
- [Gender Shades (MIT Media Lab)](https://gendershades.org/overview.html)
- [NIST FRVT Demographic Effects (2019)](https://www.nist.gov/publications/face-recognition-vendor-test-frvt-part-3-demographic-effects)
- [NIST FRTE Ongoing (2024)](https://pages.nist.gov/frvt/html/frvt11.html)
- [The Washington Post (2025) - AI chatbots and mental health](https://www.washingtonpost.com/technology/2025/02/24/ai-chatbots-mental-health-crisis/)
- [NPR (2024) - Character.AI lawsuit](https://www.npr.org/2024/10/30/nx-s1-5170279/character-ai-lawsuit)
- [AP News (2025) - AI chatbot lawsuits and mental health](https://apnews.com/article/ai-chatbots-lawsuits-mental-health)
