---
title: 'AI och etik - Case-diskussion'
description: 'Tre case om ansvar, rättvisa och mänsklig påverkan i AI-system.'
order: 5
tags:
  - etik
  - konsekvenser
  - diskussion
  - uppgift
---

## Case-diskussion: AI och etik

Arbeta i grupper om 3-4 personer. Läs ert case, diskutera frågorna och förbered en kort redovisning (2 minuter).

---

### Case 1: Vem bär ansvaret?

<details>
<summary><strong>Bakgrund</strong></summary>

En vårdcentral använder ett AI-system som hjälper till att prioritera patienter. Systemet markerar en patient som "låg risk" trots tydliga symptom. Patienten får vänta för länge och tillståndet förvärras.

Läkaren säger: "Jag litade på systemet."
Vårdcentralen säger: "Systemet är bara ett stöd."
Företaget säger: "Användaren måste göra slutbedömningen."

</details>

**Diskussionsfrågor:**
1. Vem har störst ansvar i situationen?
2. Ska ansvar delas, och i så fall hur?
3. Vad hade behövts för att felet skulle kunna förebyggas?

---

### Case 2: Är det rättvist?

<details>
<summary><strong>Bakgrund</strong></summary>

En kommun använder AI för att välja vilka CV:n som går vidare i en första gallring till sommarjobb. Efter en tid upptäcker man att elever från vissa områden nästan aldrig kallas till intervju.

Kommunen hävdar att systemet är "effektivt" och sparar tid. Samtidigt upplever många att urvalet blivit orättvist och svårt att förstå.

</details>

**Diskussionsfrågor:**
1. Är ett snabbt urval värt risken för diskriminering?
2. Hur transparent måste ett AI-system vara när det påverkar människors möjligheter?
3. Vad borde kommunen göra nu?

---

### Case 3: AI som samtalspartner

<details>
<summary><strong>Bakgrund</strong></summary>

En elev använder en AI-chatt varje kväll för att prata om stress, ensamhet och ångest. Eleven tycker att AI:n "alltid lyssnar". Efter några månader börjar eleven dra sig undan vänner och vuxna.

När skolan får veta detta uppstår en konflikt:
- Vissa menar att AI-stödet ändå hjälpte eleven.
- Andra menar att beroendet ökade problemen.

</details>

**Diskussionsfrågor:**
1. När går ett stöd över till att bli skadligt?
2. Vem borde ha ansvar för skyddsräcken i sådana tjänster?
3. Hur kan man kombinera AI-stöd med mänskligt stöd på ett bättre sätt?

---

## Redovisning i helklass

Varje grupp presenterar:
- Hur ni fördelade ansvar mellan olika aktörer.
- Vilket etiskt perspektiv som vägde tyngst i er analys.
- Ett konkret förslag på regel, designändring eller arbetssätt som minskar risken för att det händer igen.

---

## Exit ticket (individuellt)

Svara kort på frågan:

> Vilket av de tre casen tycker du är svårast att lösa rättvist, och varför?
