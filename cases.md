Bakgrund
En skola i USA lånade ut laptops till sina elever. I datorerna fanns en funktion som kunde:

    ta bilder via webbkameran
    ta skärmdumpar
    aktiveras på distans av skolan

Skolan sa att funktionen var till för att hitta stulna datorer.

Men i praktiken togs , många när elever var hemma – i sina sovrum.
Elever och föräldrar visste inte om detta.

När det upptäcktes blev det en stor skandal och skolan tvingades betala skadestånd.

Diskussionsfrågor (grupp)

1. Hade skolan rätt att använda kameran? Var går gränsen?
2. Spelar det roll att det var en skola och inte ett företag?
3. Är det okej om syftet är “säkerhet”? När blir säkerhet övervakning?
4. Hur hade detta upplevts om det hände i Sverige?

Koppling till AI

    Om bilderna hade analyserats automatiskt med AI:
    Ansiktsigenkänning
    Identifiering av personer i rummet
    Analys av beteende



Hur förändras situationen när:

    ingen människa tittar direkt?
    beslut fattas automatiskt?

    Case 2
    Viktor Arohlén
    •
    2 feb.
    100 poäng
    (23andMe – genetisk data och dataläcka)
    Bakgrund:
    Företaget 23andMe säljer DNA-test:

        Man skickar in saliv
        Får veta släktskap, ursprung, hälsoriske

    2023 fick hackare tillgång till data från miljontals användare.

    Inte bara namn och mejl – utan:

        genetisk information
        släktrelationer
        etnisk bakgrund

    Problemet:

    Om i familjen testat sitt DNA kan information om avslöjas.

    Diskussionsfrågor (grupp)

    1. Är DNA “mer privat” än annan data? Varför / varför inte?
    2. Vem äger egentligen genetisk information – du, din familj eller företaget?
    3. Borde vissa typer av data inte få samlas in alls?
    4. Skulle du själv göra ett DNA-test? Vad skulle få dig att tveka?

    Koppling till AI

        AI används redan för att:
        analysera genetiska mönster
        förutspå sjukdomsrisker
        gruppera människor efter biologiska drag



    Tänk framåt:

        Försäkringsbolag?
        Arbetsgivare?
        Staten?

        Case 3
        Viktor Arohlén
        •
        2 feb.
        100 poäng
        Svenskt case: Skolplattformen i Stockholm
        Bakgrund
        Stockholms stad införde en digital plattform för skolor:.

        Den skulle samla:

            schema
            närvaro
            omdömen
            kommunikation mellan lärare, elever och vårdnadshavare

        Men det visade sig att:

            väldigt mycket persondata samlades in
            det var oklart vem som hade tillgång till vad
            säkerheten kritiserades
            externa utvecklare kunde relativt enkelt komma åt data

        Projektet blev extremt dyrt och starkt kritiserat – och är idag ett på digitalisering utan tillräcklig hänsyn till integritet.

        Diskussionsfrågor (grupp)

        1. Är det okej att samla data bara för att det är praktiskt?
        2. Vad är extra känsligt när det gäller barn och unga?
        3. Vem bär ansvaret – kommunen, företaget eller staten?
        4. Hade detta varit mer okej om systemet “fungerade bra”?


        Koppling till AI

        Även om Skolplattformen inte var ett AI-system:

        samma data används av AI för att:

            förutspå studieresultat
            identifiera “risk-elever”
            föreslå åtgärder automatiskt

        Diskutera:

            När blir stöd → övervakning?
            Kan AI förstärka fördomar om elever?
